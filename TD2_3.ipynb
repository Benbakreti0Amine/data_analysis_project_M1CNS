{"cells":[{"cell_type":"markdown","metadata":{"id":"WcBBqHK47npl"},"source":["# Advanced clustering on real-world data\n","\n","For this practical, you will work in groups (between 2 and 4). You will apply the questions in this notebook to your assigned dataset. (Note that some of the datasets are very large (>10k samples). This might make the execution of some algorithms very slow. If that is the case, do not hesitate to talk to your teacher.)"]},{"cell_type":"markdown","metadata":{"id":"WZe0qy7e8BGa"},"source":["**To choose the dataset, you can choose among the following ones: https://docs.google.com/spreadsheets/d/1T7olHgBGIZ4gIPOnrX2jRmUmRwMUi07_DwL43N0pK6s/edit?usp=sharing.**\n","\n","**Once you have chosen your dataset and your team members, you should confirm it with your TD instructor.**\n","\n","Then, you can register in eCampus with the corresponding group.\n","\n","**You should upload this notebook filled in eCampus before Sunday 3 November at 11.59pm.**\n","\n","If the submission in eCampus is not working, you can send it to either **massinissa.hamidi@univ-evry.fr** or **clement.bernard@univ-evry.fr**\n"]},{"cell_type":"markdown","metadata":{"id":"2xxDgKZV8BGb"},"source":["We will spend two practical sessions on this notebook: during the first session, you will apply K-Means and Hierarchical clustering. During the second session, you will apply Spectral clustering and compare your obtained results.\n","\n","Most cells in this notebook are blank, you must fill them in either with code or with written interpretation. Your grade will mostly depend on the quality of your interpretations, make sure to relate your conclusions to the context of your dataset."]},{"cell_type":"markdown","metadata":{"id":"aN9tGsOndt1Q"},"source":["## TD2 (part II): K-means and Hierarchical clustering\n"]},{"cell_type":"markdown","metadata":{"id":"M3e0AXtidt1U"},"source":["### Package import"]},{"cell_type":"markdown","metadata":{"id":"cGTYtotIRPoy"},"source":["**Tip**: look at the documentation of the packages and methods imported, they can help you answer some questions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wv8EMmndt1W"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n","from sklearn.metrics import silhouette_score\n","from sklearn.preprocessing import LabelEncoder, StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"im2nvK9ldt1W"},"source":["Load the dataset, separate the labels from the variables. In some cases, you might also want to drop some variables (e.g. names, identifiers, anything that has one unique value per sample that will not help you form groups)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9LOItPsdt1W"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"raVit0J7dt1X"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5jDdbDKcdt1X"},"source":["### Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"pkQ3dSAFdt1X"},"source":["Visualize the 10 first rows of both data and classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjrPAKgkdt1X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2WoyTNqdt1X"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"az93YL1Cdt1Y"},"source":["Are there any missing values (in data)? What type are the variables?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_xrw3X0dt1Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3r5hAPHxdt1Y"},"source":["Use the describe method and explain what you obtain."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SajknQbdt1Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"guaVuYTogJ9v"},"source":["If your dataset contains missing data, follow the process seen in the first practical to impute missing data. Make sure to impute numeric and nominal data with different strategies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PphE1SI8gJWS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPlnaQDpgaJ8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EzsO2pfTgari"},"source":["Explain your choice of imputation strategy for each data type."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJ2GwVX-gkMp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QA0BnGXFdt1Y"},"source":["Do you think the data should be scaled? If yes, do it and compare the obtained data to the original data (compare only the first 20 features if the dataset is large)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tz5Fx2L0dt1Z"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"9VTyMHWCdt1Z"},"source":["How many classes are there? Plot the distribution of the classes. Is the data balanced or imbalanced?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1wYPf11dt1Z"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kr3MFvosdt1Z"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3lIVN6Cdt1a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EPPgJ5DKdt1a"},"source":["Encode your classes into a numerical variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56Wwczohdt1a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_sxbXkjZdt1a"},"source":["Check if your data and classes are numpy arrays. If that is not the case, transform your data and classes into numpy arrays."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8N-du6Udt1a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ge7xug8Mdt1a"},"source":["### Clustering algorithm 1: K-means"]},{"cell_type":"markdown","metadata":{"id":"wnFtJi8mdt1b"},"source":["Apply the K-means algorithm with 2 centers. Look at the default parameters the method takes. Make sure the algorithm doesn't run more than 500 iterations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryTO8azedt1b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87uEFkz5dt1b"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"b_-8_xoFdt1b"},"source":["What does the max_iter parameter do?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaiQ-TcEdt1c"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ko1U5rDxdt1c"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBE_F41Odt1c"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Vp8cebHpdt1d"},"source":["In order to optimize our clusters, we want to apply the silhouette method to obtain the optimal number of centers.\n","Apply silhouette on a range from 2 to 10 centers, display the average silhouette score for each and display the silhouette plot for each center.\n","<br> For some help, look at the silhouette documentation in scikit learn: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n","\n","<br>\n","\n","Please note that the code below is NOT complete. Fill in the missing parts (they are indicated by ### TO COMPLETE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJbLZkfodt1d"},"outputs":[],"source":["range_n_clusters =   ### TO COMPLETE\n","\n","import matplotlib.cm as cm\n","from sklearn.metrics import silhouette_samples\n","\n","\n","for n_clusters in range_n_clusters:\n","    # Create a plot\n","    fig, ax  = plt.subplots(1,1, figsize=(8,6))\n","\n","    # This plot is the silhouette plot\n","    # The silhouette coefficient can range from -1, 1 but in this example all\n","    # lie within [-0.1, 1]\n","    ax.set_xlim([-0.1, 1])\n","    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","    # plots of individual clusters, to demarcate them clearly.\n","    ax.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n","\n","    # Initialize the clusterer with n_clusters.\n","    clusterer =  ### TO COMPLETE\n","    cluster_labels = ### TO COMPLETE\n","\n","    # The silhouette_score gives the average value for all the samples.\n","    # This gives a perspective into the density and separation of the formed\n","    # clusters\n","    silhouette_avg = ### TO COMPLETE\n","    print(\"For n_clusters =\", n_clusters,\n","          \"The average silhouette_score is :\", silhouette_avg)\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = ### TO COMPLETE\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Aggregate the silhouette scores for samples belonging to\n","        # cluster i, and sort them\n","        ith_cluster_silhouette_values = \\\n","            sample_silhouette_values[cluster_labels == i]\n","\n","        ith_cluster_silhouette_values.sort()\n","\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax.fill_betweenx(np.arange(y_lower, y_upper),\n","                          0, ith_cluster_silhouette_values,\n","                          facecolor=color, edgecolor=color, alpha=0.7)\n","\n","        # Label the silhouette plots with their cluster numbers at the middle\n","        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","    ax.set_title(\"The silhouette plot for the various clusters.\")\n","    ax.set_xlabel(\"The silhouette coefficient values\")\n","    ax.set_ylabel(\"Cluster label\")\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    ax.set_yticks([])  # Clear the yaxis labels / ticks\n","    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","    plt.title((\"Silhouette analysis for KMeans clustering on sample data \"\n","                  \"with n_clusters = %d\" % n_clusters),\n","                 fontsize=14, fontweight='bold')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"amwfGBJEdt1e"},"source":["What is, in your opinion, the best number of centers to choose?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z68zLa0bdt1e"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IirgOmZSdt1e"},"source":["Apply K-means again with the optimal number of centers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGXzLpygdt1e"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"skrloWHedt1e"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPu9IZ64dt1f"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"NiHJK5jTdt1f"},"source":["Since, the true class of each sample is known, we can use them to evaluate the clustering results we obtained.\n","<br>\n","1- Give the contingency matrix of the clustering."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tionJSeKdt1f"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"pLPxt1GIdt1f"},"source":["2- Discuss the obtained matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytYboFPMdt1g"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0JAqYzj2dt1g"},"source":["With clustering being an unsupervised learning method, classification evaluation metrics (accuracy, precision, etc) are not appropriate. Instead, we can use clustering evaluation metrics (rand index, adjusted rand index, homogeneity, completeness and V-measure).\n","<br>\n","Check the scikit learn documentation to understand each score: https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n","<br>\n","3- Compute all metrics defined above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9yoAoU6dt1g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91HwHL46dt1g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNdN-xzRdt1g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHsePLXZdt1g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEACuEprdt1g"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5MiEiC3_dt1g"},"source":["4- Discuss the obtained scores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P9tCoBRDdt1g"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XaccLkb2dt1g"},"source":["### Clustering algorithm 2: Hierarchical clustering"]},{"cell_type":"markdown","metadata":{"id":"F8Bo1aEVdt1h"},"source":["Apply the hierarchical clustering algorithm with 2 centers. Look at the default parameters and make sure the algorithm is based on the single linkage method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjFkebb6dt1h"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ly4YgS-Hdt1h"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ufqlJ8P-dt1h"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8KNOGSodt1h"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"dcLAYRM_dt1h"},"source":["Apply the hierarchical clustering algorithm again. This time,  change the linkage method to complete linkage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O83wL-uYdt1h"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haOIRUyZdt1h"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YSD0GRBNdt1h"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xb3-YefZdt1i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"iLt5Qyn1dt1i"},"source":["Apply the hierarchical clustering algorithm once again. This time, change the linkage method to ward linkage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GNFm9L-dt1i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XPcekqDKdt1i"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_SUB7_0dt1i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_6473o0edt1i"},"source":["Compare the three results. Is the type of linkage method used important? Which one gave you the best result? For the rest of this section, use the best linkage method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpli7Hw9dt1i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ol58-yfHdt1i"},"source":["In order to optimize our clusters, we want to apply the silhouette method to obtain the optimal number of centers.\n","Apply silhouette on a range from 2 to 10 centers, display the average silhouette score for each and display the silhouette plot for each center.\n","<br> For some help, look at the silhouette documentation in scikit learn: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n","\n","<br>\n","\n","Please note that the code below is NOT complete. Fill in the missing parts (they are indicated by ### TO COMPLETE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HanoMKnSdt1j"},"outputs":[],"source":["range_n_clusters =   ### TO COMPLETE\n","\n","import matplotlib.cm as cm\n","from sklearn.metrics import silhouette_samples\n","\n","\n","for n_clusters in range_n_clusters:\n","    # Create a plot\n","    fig, ax  = plt.subplots(1,1, figsize=(8,6))\n","\n","    # This plot is the silhouette plot\n","    # The silhouette coefficient can range from -1, 1 but in this example all\n","    # lie within [-0.1, 1]\n","    ax.set_xlim([-0.1, 1])\n","    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","    # plots of individual clusters, to demarcate them clearly.\n","    ax.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n","\n","    # Initialize the clusterer with n_clusters and the linkage method you\n","    # determined worked best.\n","    clusterer =  ### TO COMPLETE\n","    cluster_labels = ### TO COMPLETE\n","\n","    # The silhouette_score gives the average value for all the samples.\n","    # This gives a perspective into the density and separation of the formed\n","    # clusters\n","    silhouette_avg = ### TO COMPLETE\n","    print(\"For n_clusters =\", n_clusters,\n","          \"The average silhouette_score is :\", silhouette_avg)\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = ### TO COMPLETE\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Aggregate the silhouette scores for samples belonging to\n","        # cluster i, and sort them\n","        ith_cluster_silhouette_values = \\\n","            sample_silhouette_values[cluster_labels == i]\n","\n","        ith_cluster_silhouette_values.sort()\n","\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax.fill_betweenx(np.arange(y_lower, y_upper),\n","                          0, ith_cluster_silhouette_values,\n","                          facecolor=color, edgecolor=color, alpha=0.7)\n","\n","        # Label the silhouette plots with their cluster numbers at the middle\n","        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","    ax.set_title(\"The silhouette plot for the various clusters.\")\n","    ax.set_xlabel(\"The silhouette coefficient values\")\n","    ax.set_ylabel(\"Cluster label\")\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    ax.set_yticks([])  # Clear the yaxis labels / ticks\n","    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","    plt.title((\"Silhouette analysis for Hierarchical clustering on sample data \"\n","                  \"with n_clusters = %d\" % n_clusters),\n","                 fontsize=14, fontweight='bold')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Tp0wH_hVdt1j"},"source":["What is, in your opinion, the best number of centers to choose?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5j2Gt5endt1j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mOs17xDmdt1j"},"source":["Apply hierarchical clustering again with the optimal number of centers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYgGPNQUdt1j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"4ARkrgljdt1j"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdDCA4todt1j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tngeGHEtdt1k"},"source":["Since, the true class of each sample is known, we can use them to evaluate the clustering results we obtained.\n","<br>\n","1- Give the contingency matrix of the clustering."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nm0Pa9l_dt1k"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"K9eXmNPedt1k"},"source":["2- Discuss the obtained matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwpYMLlmdt1k"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QHQPy1yFdt1k"},"source":["With clustering being an unsupervised learning method, classification evaluation metrics (accuracy, precision, etc) are not appropriate. Instead, we can use clustering evaluation metrics (rand index, adjusted rand index, homogeneity, completeness and V-measure).\n","<br>\n","Check the scikit learn documentation to understand each score: https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n","<br>\n","3- Compute all metrics defined above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHdQ54I4dt1k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20C5vz4-dt1k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSSYsrbwdt1k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dd2pQI5sdt1k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GiOFk5fqdt1k"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TA7Ahyq5uiyy"},"source":["4- Discuss the obtained scores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ml3a2nv2dt1l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Mg1tkFJHdt1l"},"source":["OPTIONAL: plot the dendrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCeSwjpPdt1l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CRZAZ0QYY2po"},"source":["## TD3 (part II): Spectral clustering and comparison"]},{"cell_type":"markdown","metadata":{"id":"2VY6BQRLVk1_"},"source":["### Clustering algorithm 3: Spectral clustering"]},{"cell_type":"markdown","metadata":{"id":"hjcboItnWDEb"},"source":["Apply the spectral clustering algorithm with 2 centers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbhL_xQTWDEm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THN7foyCWDEm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Tt-JvXeSWDEm"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkVwxwZYWDEm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bR4lOKf8WDEm"},"source":["Apply the spectral clustering algorithm again. This time, change the method to construct the affinity matrix to \"nearest_neighbors\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5IZ5kKhWDEm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sd1vodyjWDEm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"gE16eybiWDEn"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VV4fawy5WDEn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_oDzw16yWDEn"},"source":["Compare the two results. Is the method used to construct the affinity matrix important? Which one gave you the best result? For the rest of this section, use the best method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeyOAE3GVHfa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qtZN2Dt7VHfa"},"source":["In order to optimize our clusters, we want to apply the silhouette method to obtain the optimal number of centers.\n","Apply silhouette on a range from 2 to 10 centers, display the average silhouette score for each and display the silhouette plot for each center.\n","<br> For some help, look at the silhouette documentation in scikit learn: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n","\n","<br>\n","\n","Please note that the code below is NOT complete. Fill in the missing parts (they are indicated by ### TO COMPLETE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"he4dLDP0WQbJ"},"outputs":[],"source":["range_n_clusters =   ### TO COMPLETE\n","\n","import matplotlib.cm as cm\n","from sklearn.metrics import silhouette_samples\n","\n","\n","for n_clusters in range_n_clusters:\n","    # Create a plot\n","    fig, ax  = plt.subplots(1,1, figsize=(8,6))\n","\n","    # This plot is the silhouette plot\n","    # The silhouette coefficient can range from -1, 1 but in this example all\n","    # lie within [-0.1, 1]\n","    ax.set_xlim([-0.1, 1])\n","    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","    # plots of individual clusters, to demarcate them clearly.\n","    ax.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n","\n","    # Initialize the clusterer with n_clusters. Make sure you use the \"affinity\"\n","    # method that gave you the best results.\n","    clusterer =  ### TO COMPLETE\n","    cluster_labels = ### TO COMPLETE\n","\n","    # The silhouette_score gives the average value for all the samples.\n","    # This gives a perspective into the density and separation of the formed\n","    # clusters\n","    silhouette_avg = ### TO COMPLETE\n","    print(\"For n_clusters =\", n_clusters,\n","          \"The average silhouette_score is :\", silhouette_avg)\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = ### TO COMPLETE\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Aggregate the silhouette scores for samples belonging to\n","        # cluster i, and sort them\n","        ith_cluster_silhouette_values = \\\n","            sample_silhouette_values[cluster_labels == i]\n","\n","        ith_cluster_silhouette_values.sort()\n","\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax.fill_betweenx(np.arange(y_lower, y_upper),\n","                          0, ith_cluster_silhouette_values,\n","                          facecolor=color, edgecolor=color, alpha=0.7)\n","\n","        # Label the silhouette plots with their cluster numbers at the middle\n","        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","    ax.set_title(\"The silhouette plot for the various clusters.\")\n","    ax.set_xlabel(\"The silhouette coefficient values\")\n","    ax.set_ylabel(\"Cluster label\")\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    ax.set_yticks([])  # Clear the yaxis labels / ticks\n","    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","    plt.title((\"Silhouette analysis for Spectral clustering on sample data \"\n","                  \"with n_clusters = %d\" % n_clusters),\n","                 fontsize=14, fontweight='bold')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jU6gbfyQWQbK"},"source":["What is, in your opinion, the best number of centers to choose?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qBJUllfWQbK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Vziu4TUAWQbK"},"source":["Apply spectral clustering again with the optimal number of centers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzIxk0-ZWQbK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bIj4diQPWQbK"},"source":["How many samples are in each cluster?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsE0gExJWQbK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"U2G_hr1gWQbK"},"source":["Since, the true label of each sample is known, we can use them to evaluate the clustering results we obtained.\n","<br>\n","1- Give the contingency matrix of the clustering."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LE0UbLRtWQbK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"q0Ys0ySzWQbK"},"source":["2- Discuss the obtained matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0j4ebHfdWQbK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TtvJnVkvWQbL"},"source":["With clustering being an unsupervised learning method, classification evaluation metrics (accuracy, precision, etc) are not appropriate. Instead, we can use clustering evaluation metrics (rand index, adjusted rand index, homogeneity, completeness and V-measure).\n","<br>\n","Check the scikit learn documentation to understand each score: https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n","<br>\n","3- Compute all metrics defined above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLimIcpwWQbL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1zTlVXeWQbL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kdDG4OSrWQbL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtHlWL1vWQbL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZ8YuRcpWQbL"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZmJcypxCWQbL"},"source":["4- Discuss the obtained scores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvgmvB6lWQbL"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_kcICxJzdt1l"},"source":["### Conclusion"]},{"cell_type":"markdown","metadata":{"id":"krsclwDKdt1l"},"source":["In your opinion, which method gave the better results for this dataset?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whgL_5rRaU5Z"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"G18kvlZUdt1l"},"source":["Usually, when we apply different clustering methods, it's because we do not know the classes. In such situation, we compare the different clustering models we obtained with each method to each other to see if they are corroborating.\n","<br>\n","Pick two of the three clustering methods used above, and use the same metrics as before to compare them (do not rerun the models, just compare the predicted clusters you obtained with each method).  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsXCWPg0dt1l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f32kQiPgdt1l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"easyNwHodt1l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSDPgx1odt1l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmDQUR5adt1l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"G1B2Y1vGdt1m"},"source":["Discuss the obtained scores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqV03WEmdt1m"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"W56hZQxZdt1m"},"source":["At the beginning of the practical, you noticed the number of classes in the data. After completing all the work, applying silhouette and finding the optimal number of clusters, were you expecting the results you obtained? Can you find an explanation for the result?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Ysemk8ddt1m"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"py39","language":"python","name":"py39"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}